{
  "nbformat": 4,
  "nbformat_minor": 2,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.8"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# HealthGPT Colab Quickstart Notebook\n",
        "\n",
        "This notebook walks through installing dependencies, running a quick inference demo, and training/inferencing the comprehension, NER, and generation models on vlhealth-style data.\n",
        "\n",
        "Sections:\n",
        "1. Setup: install libs & clone repo\n",
        "2. Quick verification (small models)\n",
        "3. Train comprehension classifier (example)\n",
        "4. Train NER model (example)\n",
        "5. Train generation model (example)\n",
        "6. Inference using trained checkpoints\n",
        "7. Optional: run FastAPI + ngrok\n",
        "\n",
        "Notes: Use a GPU runtime for training. Adjust batch sizes / epochs for Colab memory constraints."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# 1) Install dependencies and clone the repo\n",
        "!pip install -q transformers datasets evaluate torch accelerate fastapi uvicorn pyngrok nest_asyncio\n",
        "!rm -rf HealthGPT\n",
        "!git clone https://github.com/SathwikGudidevuni/HealthGPT.git"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2) Quick verification (recommended)\n",
        "This runs a lightweight inference test using small/distilled models so the notebook is quick and fits Colab memory.\n",
        "It does NOT require training."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Use smaller models to avoid OOM\n",
        "import os, sys\n",
        "sys.path.append('/content/HealthGPT')\n",
        "os.environ['COMPREHENSION_ZS_MODEL'] = 'valhalla/distilbart-mnli-12-1'\n",
        "os.environ['GENERATION_MODEL'] = 't5-small'\n",
        "\n",
        "from app.pipeline import HealthPipeline\n",
        "print('Initializing pipeline (may download models)...')\n",
        "pipe = HealthPipeline()\n",
        "\n",
        "examples = [\n",
        "    \"I've been feeling dizzy and have a mild fever for two days.\",\n",
        "    \"My throat hurts and I have a headache since yesterday.\",\n",
        "    \"What medicine should I take for my headache?\"\n",
        "]\n",
        "from pprint import pprint\n",
        "for text in examples:\n",
        "    print('\\n=== USER INPUT ===')\n",
        "    print(text)\n",
        "    res = pipe.run(text)\n",
        "    print('\\n-- CONTEXT --')\n",
        "    pprint(res['context'])\n",
        "    print('\\n-- RESPONSE --')\n",
        "    print(res['response'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3) Train comprehension classifier (example)\n",
        "This runs the train_comprehension.py script. For quick experiments, use the sample CSVs in data/. Increase epochs/adjust lr_grid for real vlhealth data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Example training command (adjust paths for your data)\n",
        "!python /content/HealthGPT/train/train_comprehension.py \\\n",
        "  --train_csv /content/HealthGPT/data/sample_comp_train.csv \\\n",
        "  --val_csv /content/HealthGPT/data/sample_comp_train.csv \\\n",
        "  --output_dir /content/outputs/comp_classifier \\\n",
        "  --model_name bert-base-uncased \\\n",
        "  --num_train_epochs 1 \\\n",
        "  --lr_grid 5e-5,3e-5,2e-5 \\\n",
        "  --per_device_train_batch_size 4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4) Train NER (token-classification) example\n",
        "Prepare NER JSON or CSV with tokens and ner_tags as described in train/train_ner.py."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Example NER training command (requires proper dataset)\n",
        "# !python /content/HealthGPT/train/train_ner.py \\\n",
        "#   --train_json /content/HealthGPT/data/ner_train.json \\\n",
        "#   --val_json /content/HealthGPT/data/ner_val.json \\\n",
        "#   --output_dir /content/outputs/ner_model \\\n",
        "#   --model_name dslim/bert-base-NER \\\n",
        "#   --num_train_epochs 3 \n",
        "print('Skip NER training by default; add your dataset and uncomment the command above')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5) Train generation model (example)\n",
        "Train the seq2seq generator (T5/Flan-T5) on input_text -> target_text. Use small models for Colab."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Example generation training (adjust to your dataset)\n",
        "!python /content/HealthGPT/train/train_generation.py \\\n",
        "  --train_csv /content/HealthGPT/data/sample_gen_train.csv \\\n",
        "  --val_csv /content/HealthGPT/data/sample_gen_train.csv \\\n",
        "  --output_dir /content/outputs/gen_t5 \\\n",
        "  --model_name t5-small \\\n",
        "  --num_train_epochs 1 \\\n",
        "  --per_device_train_batch_size 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6) Inference with trained checkpoints\n",
        "After training, set the COMP_CLASSIFIER_PATH, COMP_NER_PATH and GENERATION_MODEL env vars and run the pipeline."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Example: point to trained outputs and run inference\n",
        "import os, sys\n",
        "sys.path.append('/content/HealthGPT')\n",
        "# adjust these paths based on your actual training outputs\n",
        "os.environ['COMP_CLASSIFIER_PATH'] = '/content/outputs/comp_classifier/lr_3e-05'\n",
        "os.environ['COMP_NER_PATH'] = '/content/outputs/ner_model'\n",
        "os.environ['GENERATION_MODEL'] = '/content/outputs/gen_t5'\n",
        "from app.pipeline import HealthPipeline\n",
        "pipe = HealthPipeline()\n",
        "res = pipe.run(\"I have a sore throat and a low fever for two days.\")\n",
        "from pprint import pprint\n",
        "pprint(res)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7) Optional: run FastAPI in Colab and expose via ngrok\n",
        "Only do this if models fit in memory. This starts the API and gives you a public URL."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Optional: start FastAPI + ngrok\n",
        "from pyngrok import ngrok\n",
        "import nest_asyncio, uvicorn, threading, os, sys\n",
        "sys.path.append('/content/HealthGPT')\n",
        "# create public tunnel\n",
        "public_url = ngrok.connect(8000).public_url\n",
        "print('ngrok public URL:', public_url)\n",
        "nest_asyncio.apply()\n",
        "def run_uvicorn():\n",
        "    uvicorn.run('app.api:app', host='0.0.0.0', port=8000, log_level='info')\n",
        "t = threading.Thread(target=run_uvicorn, daemon=True)\n",
        "t.start()\n",
        "print('uvicorn started')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Notes & troubleshooting\n",
        "- If you see CUDA OOM errors, reduce batch sizes or force CPU by running `os.environ['CUDA_VISIBLE_DEVICES']=''` before importing torch/transformers.\n",
        "- First-run downloads may take several minutes.\n",
        "- To persist outputs across Colab sessions, mount Google Drive and copy /content/outputs to Drive.\n",
        "- For real vlhealth experiments, increase --num_train_epochs, tune lr_grid, and gather more labeled data."
      ]
    }
  ]
}
